#!/usr/bin/env python3
"""Simple test for Reranker model loading and functionality."""

import sys
import time
from pathlib import Path

# Add parent directory to path before importing askany
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from askany.config import settings

    model_name = settings.reranker_model
    reranker_type = settings.reranker_type
except ImportError:
    # Fallback to default model if can't import config
    model_name = "BAAI/bge-reranker-v2-m3"
    reranker_type = "sentence_transformer"
    print("âš ï¸  Could not import askany.config, using default model:", model_name)

print("=" * 60)
print("Testing Reranker Model Loading")
print("=" * 60)

try:
    from llama_index.core.postprocessor import SentenceTransformerRerank
    import torch

    print("\n1. Checking dependencies...")
    print("   âœ… llama_index: OK")
    print("   âœ… torch: OK")

    print("\n2. Checking CUDA...")
    if torch.cuda.is_available():
        device = "cuda"
        print(f"   âœ… CUDA available: {torch.cuda.get_device_name(0)}")
    else:
        device = "cpu"
        print("   â„¹ï¸  Using CPU")

    print("\n3. Loading reranker model (this may download if not cached)...")
    print(f"   Model: {model_name}")
    print(f"   Type: {reranker_type}")
    print(
        "   (First time will download from HuggingFace, this may take a few minutes...)"
    )

    start_time = time.time()
    reranker = SentenceTransformerRerank(
        model=model_name,
        top_n=5,  # Test with top 5
        trust_remote_code=True,  # Required for BGE models
        device=device,
    )
    load_time = time.time() - start_time

    print(f"   âœ… Model loaded successfully in {load_time:.2f} seconds!")

    print("\n4. Testing reranker functionality...")
    # Create mock nodes for testing
    from llama_index.core.schema import NodeWithScore, TextNode

    query = "å¦‚ä½•è§£å†³ç½‘ç»œè¿æ¥é—®é¢˜ï¼Ÿ"
    test_nodes = [
        NodeWithScore(
            node=TextNode(
                text="ç½‘ç»œè¿æ¥é—®é¢˜çš„è§£å†³æ–¹æ¡ˆåŒ…æ‹¬æ£€æŸ¥ç½‘ç»œé…ç½®ã€é‡å¯ç½‘ç»œæœåŠ¡ç­‰ã€‚",
                metadata={"source": "faq_1"},
            ),
            score=0.8,
        ),
        NodeWithScore(
            node=TextNode(
                text="æ•°æ®åº“è¿æ¥é”™è¯¯é€šå¸¸æ˜¯ç”±äºé…ç½®ä¸æ­£ç¡®æˆ–æœåŠ¡æœªå¯åŠ¨å¯¼è‡´çš„ã€‚",
                metadata={"source": "faq_2"},
            ),
            score=0.7,
        ),
        NodeWithScore(
            node=TextNode(
                text="ç½‘ç»œè¿æ¥é—®é¢˜å¯ä»¥é€šè¿‡pingå‘½ä»¤æµ‹è¯•ç½‘ç»œè¿é€šæ€§ï¼Œæ£€æŸ¥é˜²ç«å¢™è®¾ç½®ã€‚",
                metadata={"source": "faq_3"},
            ),
            score=0.9,
        ),
        NodeWithScore(
            node=TextNode(
                text="ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–åŒ…æ‹¬å†…å­˜ç®¡ç†ã€CPUä½¿ç”¨ç‡ç›‘æ§ç­‰ã€‚",
                metadata={"source": "faq_4"},
            ),
            score=0.5,
        ),
        NodeWithScore(
            node=TextNode(
                text="ç½‘ç»œé…ç½®éœ€è¦æ£€æŸ¥IPåœ°å€ã€å­ç½‘æ©ç ã€ç½‘å…³ç­‰å‚æ•°ã€‚",
                metadata={"source": "faq_5"},
            ),
            score=0.4,
        ),
    ]

    print(f"   Query: '{query}'")
    print(f"   Input nodes: {len(test_nodes)}")
    print("   Original scores:", [f"{n.score:.2f}" for n in test_nodes])

    # Test reranking
    from llama_index.core import QueryBundle

    query_bundle = QueryBundle(query)
    start_time = time.time()
    reranked_nodes = reranker.postprocess_nodes(test_nodes, query_bundle)
    rerank_time = time.time() - start_time

    print(f"   âœ… Reranking completed in {rerank_time:.3f} seconds")
    print(f"   Output nodes: {len(reranked_nodes)}")
    print("   Reranked scores:", [f"{n.score:.2f}" for n in reranked_nodes])

    # Verify reranking changed the order
    original_order = [n.node.metadata.get("source") for n in test_nodes]
    reranked_order = [n.node.metadata.get("source") for n in reranked_nodes]
    if original_order != reranked_order:
        print("   âœ… Reranking changed the order (expected)")
    else:
        print("   âš ï¸  Reranking did not change the order")

    # Detailed analysis of each reranked node
    print("\n   ğŸ“Š Detailed Reranking Analysis:")
    print("   " + "-" * 56)
    for i, node in enumerate(reranked_nodes, 1):
        source = node.node.metadata.get("source")
        original_node = next(
            n for n in test_nodes if n.node.metadata.get("source") == source
        )
        original_score = original_node.score
        reranked_score = node.score
        score_change = reranked_score - original_score

        print(f"   {i}. {source}:")
        print(
            f"      Original score: {original_score:.2f} â†’ Reranked: {reranked_score:.4f} ({score_change:+.4f})"
        )
        print(f"      Text: {node.node.text}")

        # Analyze relevance
        if (
            "ç½‘ç»œè¿æ¥é—®é¢˜" in node.node.text
            and "è§£å†³" in node.node.text
            or "æ–¹æ¡ˆ" in node.node.text
        ):
            relevance = "âœ… é«˜åº¦ç›¸å…³ (ç›´æ¥æåˆ°'ç½‘ç»œè¿æ¥é—®é¢˜'å’Œ'è§£å†³æ–¹æ¡ˆ')"
        elif "ç½‘ç»œè¿æ¥é—®é¢˜" in node.node.text:
            relevance = "âœ… ç›¸å…³ (æåˆ°'ç½‘ç»œè¿æ¥é—®é¢˜')"
        elif "ç½‘ç»œ" in node.node.text and "é…ç½®" in node.node.text:
            relevance = "âš ï¸  éƒ¨åˆ†ç›¸å…³ (æåˆ°ç½‘ç»œé…ç½®ï¼Œä½†æœªæ˜ç¡®æ¶‰åŠ'è§£å†³è¿æ¥é—®é¢˜')"
        elif "è¿æ¥" in node.node.text and "æ•°æ®åº“" in node.node.text:
            relevance = "âŒ ä¸ç›¸å…³ (æ•°æ®åº“è¿æ¥ â‰  ç½‘ç»œè¿æ¥)"
        elif "ç³»ç»Ÿæ€§èƒ½" in node.node.text or "å†…å­˜ç®¡ç†" in node.node.text:
            relevance = "âŒ å®Œå…¨ä¸ç›¸å…³ (ä¸ç½‘ç»œè¿æ¥é—®é¢˜æ— å…³)"
        else:
            relevance = "â“ ç›¸å…³æ€§å¾…åˆ¤æ–­"

        print(f"      Relevance: {relevance}")
        print()

    # Check if top result is more relevant
    top_node = reranked_nodes[0]
    print("\n   Top reranked result:")
    print(f"   - Source: {top_node.node.metadata.get('source')}")
    print(f"   - Score: {top_node.score:.4f}")
    print(f"   - Text: {top_node.node.text[:60]}...")

    # Explanation for low scores
    print("\n   ğŸ’¡ Why are the last three scores almost 0?")
    print("   " + "-" * 56)
    print("   BGE reranker uses a cross-encoder model that performs deep semantic")
    print("   matching between query and documents. For irrelevant documents:")
    print("   1. The model assigns very low scores (close to 0) to indicate")
    print("      they are not relevant to the query")
    print("   2. This is normal behavior - the model is designed to distinguish")
    print("      between relevant and irrelevant documents")
    print("   3. Scores are typically normalized (e.g., via sigmoid), so")
    print("      irrelevant documents get scores near 0, while relevant ones")
    print("      get scores closer to 1")
    print()
    print("   In this test:")
    print("   - faq_2: Database connection â‰  Network connection (irrelevant)")
    print("   - faq_4: System performance â‰  Network connection (irrelevant)")
    print(
        "   - faq_5: Network config â‰  Solving network connection problems (weakly relevant)"
    )

    print("\n" + "=" * 60)
    print("âœ… All tests passed! Reranker is ready to use.")
    print("=" * 60)
    print("\nğŸ’¡ Note: Model is automatically downloaded from HuggingFace")
    print("   Cache location: ~/.cache/huggingface/hub/")
    print(f"   Model: {model_name}")

    # Test alternative model if specified
    if model_name != "openbmb/MiniCPM-Reranker":
        print("\n" + "=" * 60)
        print("Optional: Testing alternative model")
        print("=" * 60)
        try:
            alt_model = "openbmb/MiniCPM-Reranker"
            print(f"\nTesting alternative model: {alt_model}")
            alt_reranker = SentenceTransformerRerank(
                model=alt_model,
                top_n=5,
                trust_remote_code=True,
            )
            print(f"   âœ… Alternative model '{alt_model}' loaded successfully!")
            print("   (This model is available as an option in config)")
        except Exception as e:
            error_msg = str(e)
            print(f"   âš ï¸  Alternative model test failed: {error_msg}")

            # Provide helpful installation hints for common errors
            if "SentencePiece" in error_msg or "sentencepiece" in error_msg.lower():
                print("\n   ğŸ’¡ To use MiniCPM-Reranker, install SentencePiece:")
                print("      pip install sentencepiece")
                print("   (This is an optional dependency for this specific model)")
            elif "ImportError" in str(type(e).__name__):
                print(
                    "   ğŸ’¡ Missing dependency. Check error message above for details."
                )
            else:
                print("   (This is OK, model may need different configuration)")

except ImportError as e:
    print(f"\nâŒ Import error: {e}")
    print("   Please install: pip install llama-index sentence-transformers torch")
    sys.exit(1)
except Exception as e:
    print(f"\nâŒ Error: {e}")
    import traceback

    traceback.print_exc()
    print("\nğŸ’¡ Tips:")
    print("   1. Check internet connection (model downloads from HuggingFace)")
    print("   2. If download fails, you can manually download:")
    print(
        f"      python -c \"from llama_index.core.postprocessor import SentenceTransformerRerank; SentenceTransformerRerank(model='{model_name}', top_n=5)\""
    )
    print("   3. Model will be cached in ~/.cache/huggingface/")
    sys.exit(1)
